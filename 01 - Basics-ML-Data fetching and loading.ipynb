{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Machine Learning (Data Fetching and Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr. Sandeep Nagar's notes\n",
    "\n",
    "Ref: Hands-on machine learning with Scikit-learn and TensorFlow by Aurelien Jeron (ISBN - 978-1491962299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated downlaod of data from a database server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page: 44-45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining url to download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall work with dataset at `https://raw.githubusercontent.com/ageron/handson-ml/master/` where the folder `datasets/housing` contains the file `housing.tgz` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we shall import relevant libraries like:\n",
    "* `os` for enabling commands to work with operating system used to handle files\n",
    "* `tarfile` for enabling commands to work with compressed `.tgz` files\n",
    "* `urllib` for handling URL at whil=ch file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall store information of `url` and specific folder in which the file is stored in variables `DOWNLOAD_ROOT` and `HOUSING_PATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall use this information to locate the file by simplying adding above defined strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We havent downlaoded the file yet. We have just defined the path to dowload the same and stored it in the variable name `HOUSING_URL`. \n",
    "\n",
    "* The advantgage of writing such a structure is that it can be generalized to accesse any database on internet. It's master `url` and folder structures can be defiend and then can be used to defining the `url` to dowload the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function to fetch the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now define a python function for the purpose of fecthing the data. When called with arguments `housing_url` and `housing_path`, it will downlaod the data in a new directory `housing_path`\n",
    "\n",
    "* If the directory already exists, then it will ignore the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH): # take two inputs as url and path to file\n",
    "    if not os.path.isdir(housing_path): # if the directory \"housing_data\" does not exist then make one\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\") # make a path to tgz file\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path) # request t retrive the tgz file\n",
    "    housing_tgz = tarfile.open(tgz_path) # open the tgz file\n",
    "    housing_tgz.extractall(path=housing_path) # extract the tgz file in directory \"housing_path\"\n",
    "    housing_tgz.close() # close the trz file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run the function `fetch_housing_data` one to fetch the data and then inspect what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - Basics-ML-Data fetching and loading.ipynb\r\n",
      "LICENSE\r\n",
      "README.md\r\n",
      "\u001b[34mdatasets\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls # Unix command to list the contents of a folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the folder `datasets` has been created as per definition of function. Lets inspect the contents of the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sandeepnagar/Documents/GitHub/ML-python/datasets\n"
     ]
    }
   ],
   "source": [
    "cd datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mhousing\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that inside the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data using `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`pandas` library shall be used to handle data. It's `dataframe` object shall be used to store and manipulate data. A function shall be used to load the data as a `dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
